{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project task 05:  Clustering users based on their preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this task is to find groups of users with similar preferences using **Spectral clustering**. \n",
    "You are given a fragment of the Yelp social network, represented by an undirected weighted graph.\n",
    "Nodes in the graph represent users.\n",
    "If two users are connected by an edge of weight $w$, it means that they have both left positive reviews to the same $w$ restaurants.\n",
    "\n",
    "Additionally, you are given a matrix `F` that encodes user preferences to different categories of restaurants. If `F[i, c] = 1`, then user `i` likes restaurants in category `c`.\n",
    "\n",
    "You are allowed to use the imported functions (`eigsh`, `KMeans`, `normalize`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "* `N` = number of users (nodes in the graph)\n",
    "* `C` = number of categories\n",
    "* The graph is stored as a sparse adjacency matrix `A` (shape `[N, N]`).\n",
    "* User preferences are stored in a matrix `F` (shape `[N, C]`). They will only be used for the final part of the assignment (Part 3)\n",
    "* Name of each category is provided in the list `categories` (length `[C]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "A = sp.load_npz('task_05_data/A.npz')\n",
    "F = np.load('task_05_data/F.npy',allow_pickle=True)\n",
    "categories = np.load('task_05_data/categories.npy',allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert A.shape[0] == F.shape[0]\n",
    "assert F.shape[1] == len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementing spectral clustering\n",
    "## 1.1. Construct the graph Laplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to construct the Laplacian for the given graph. \n",
    "\n",
    "Given the **adjacency matrix** $A \\in \\mathbb{R}^{N \\times N},$ we define the **degree matrix** $D \\in \\mathbb{R}^{N \\times N}$ of an undirected graph as\n",
    "$$D_{ij} =  \\begin{cases}\\sum_{k=1}^N A_{ik} & if \\;\\; i = j\\\\ 0 & if \\;\\; i \\ne j\\end{cases}$$\n",
    "\n",
    "If our goal is to minimize the **ratio cut**, we will need to use the **unnormalized Laplacian**, defined as\n",
    "$$L_{unnorm} = D - A.$$\n",
    "\n",
    "If our goal is to minimze the **normalized cut**, we will need to use the **normalized Laplacian** (a.k.a. symmetrized Laplacian), defined as\n",
    "$$L_{sym} = I - D^{-1/2}AD^{-1/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def construct_laplacian(A, norm_laplacian):\n",
    "    \"\"\"Construct Laplacian of a graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    norm_laplacian : bool\n",
    "        Whether to construct the normalized graph Laplacian or not.\n",
    "        If True, construct the normalized (symmetrized) Laplacian, L = I - D^{-1/2} A D^{-1/2}.\n",
    "        If False, construct the unnormalized Laplacian, L = D - A.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    L : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Laplacian of the graph.\n",
    "        \n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    #assert: diag(A) == 0, should check for this\n",
    "    I = sp.identity(A.shape[0])\n",
    "    \n",
    "    if norm_laplacian:\n",
    "        #print('debug. shape of sqrt is %s, we were expecting %s'%(str(np.sqrt(np.sum(A,axis = 0)).shape),str(A.shape[0])))\n",
    "        D_sqrt = sp.diags(np.asarray( 1./np.sqrt(np.sum(A,axis = 0))).squeeze() , 0)\n",
    "        L = I - D_sqrt.multiply(A.multiply(D_sqrt))\n",
    "    else:\n",
    "        #print('debug. shape of sum is %s, we were expecting %s'%(str(np.sum(A,axis = 0).reshape(-1).shape),str(A.shape[0])))\n",
    "        #print(np.sum(A,axis = 0).toarray().squeeze().shape)\n",
    "        D = sp.diags(np.asarray(np.sum(A,axis = 0)).squeeze(), 0 )\n",
    "        L = D - A\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Spectral embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to compute the spectral embedding for the given graph.\n",
    "\n",
    "In order to partition the graph into $k$ clusters, such that the desired cut (ratio or normalized) is minimized, we need to consider the $k$ eigenvectors corresponding to the $k$ smallest eigenvalues of the graph Laplacian.\n",
    "\n",
    "Since the Laplacian matrix is sparse and symmetric, we can use the function `eigsh` from the `scipy.sparse.linalg` package in order to find eigendecomposition of $L$ (`eig` - eigendecomposition, `s` - sparse, `h`- Hermitian).\n",
    "The function `eigsh` directly allows you to find the smallest / largest eigenvalues by specifying the `k` and `which` parameters. \n",
    "\n",
    "Keep in mind that the Laplacian matrix is always positive semi-definite when picking the appropriate value for the `which` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def spectral_embedding(A, num_clusters, norm_laplacian):\n",
    "    \"\"\"Compute spectral embedding of nodes in the given graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    num_clusters : int\n",
    "        Number of clusters to detect in the data.\n",
    "    norm_laplacian : bool, default False\n",
    "        Whether to use the normalized graph Laplacian or not.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    embedding : np.array, shape [N, num_clusters]\n",
    "        Spectral embedding for the given graph.\n",
    "        Each row represents the spectral embedding of a given node.\n",
    "    \n",
    "    \"\"\"\n",
    "    if (A != A.T).sum() != 0:\n",
    "        raise ValueError(\"Spectral embedding doesn't work if the adjacency matrix is not symmetric.\")\n",
    "    \n",
    "    L = construct_laplacian(A,norm_laplacian)\n",
    "    \n",
    "    # print('debug.printing Laplacian:')\n",
    "    # print(L.shape)\n",
    "    # print(L)\n",
    "    \n",
    "    _ , eigvecs = sp.linalg.eigsh(L, k=num_clusters, M=None, \n",
    "                                         sigma=None, which='SM', v0=None, \n",
    "                                         ncv=None, maxiter=None, tol=0, return_eigenvectors=True, Minv=None, OPinv=None, mode='normal')\n",
    "    \n",
    "    #according to 1.3, if normlized laplacian was used, we should normalise the \n",
    "    # embedding matrix rowwise\n",
    "    if norm_laplacian is True:\n",
    "        eigvecs = eigvecs/np.linalg.norm(eigvecs, axis = 1).reshape(-1,1)\n",
    "        \n",
    "    # print('debug.printing embedding')\n",
    "    # print(eigvecs.shape)\n",
    "    # print(eigvecs)\n",
    "    \n",
    "    return eigvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Determine the clusters based on the spectral embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should use the K-means algorithm for assigning nodes to clusters, once the spectral embedding is computed.\n",
    "\n",
    "One thing you should keep in mind, is that when using the **normalized Laplacian**, the rows of the embedding matrix **have to** be normalized to have unit $L_2$ norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def spectral_clustering(A, num_clusters, norm_laplacian):\n",
    "    \"\"\"Perform spectral clustering on the given graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    num_clusters : int\n",
    "        Number of clusters to detect in the data.\n",
    "    norm_laplacian : bool, default False\n",
    "        Whether to use the normalized graph Laplacian or not.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    z_pred : np.array, shape [N]\n",
    "        Predicted cluster indicators for each node.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    embedding  = spectral_embedding(A, num_clusters, norm_laplacian)\n",
    "    kmeans = KMeans(n_clusters=num_clusters, init='k-means++', n_init=10, \n",
    "                    max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0,\n",
    "                    random_state=None, copy_x=True, n_jobs=None, algorithm='auto').fit(embedding[:,1:])\n",
    "    z_pred = kmeans.labels_\n",
    "    \n",
    "    return z_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quantitatively evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def labels_to_list_of_clusters(z):\n",
    "    \"\"\"Convert predicted label vector to a list of clusters in the graph.\n",
    "    This function is already implemented, nothing to do here.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z : np.array, shape [N]\n",
    "        Predicted labels.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list_of_clusters : list of lists\n",
    "        Each list contains ids of nodes that belong to the same cluster.\n",
    "        Each node may appear in one and only one partition.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> z = np.array([0, 0, 1, 1, 0])\n",
    "    >>> labels_to_list_of_clusters(z)\n",
    "    [[0, 1, 4], [2, 3]]\n",
    "    \n",
    "    \"\"\"\n",
    "    return [np.where(z == c)[0] for c in np.unique(z)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Compute ratio cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to implement functions for computing the **ratio cut** and **normalized cut** for a given partition.\n",
    "\n",
    "Ratio cut and normalized cut are defined on the slide 14 of the lecture slides.\n",
    "\n",
    "\n",
    "The function `labels_to_list_of_clusters` can be helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_ratio_cut(A, z):\n",
    "    \"\"\"Compute the ratio cut for the given partition of the graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    z : np.array, shape [N]\n",
    "        Cluster indicators for each node.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ratio_cut : float\n",
    "        Value of the cut for the given partition of the graph.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    # print('z is %s'%str(z))\n",
    "    \n",
    "    sum = 0.\n",
    "    for category in range(z.max()):\n",
    "        indices = np.argwhere(z == category).reshape(-1)\n",
    "        mask = np.ones(A.shape[0])\n",
    "        mask[indices] = 0.\n",
    "        \n",
    "        #print('debug.shapes of indices: %s . Indices is %s'%(str(indices.shape),str(indices)))\n",
    "        #print('debug. shapes of A[indices] and mask : %s , %s'%(str(A[indices].shape),str(mask.shape)))\n",
    "        cut = np.sum (A[indices]*mask)\n",
    "        cut = cut / indices.shape[0]\n",
    "        sum  = sum+cut\n",
    "        \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Compute normalized cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: if a cluster only contains a single node, define its volume to be 1 to avoid division by zero errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_normalized_cut(A, z):\n",
    "    \"\"\"Compute the normalized cut for the given partition of the graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : scipy.sparse.csr_matrix, shape [N, N]\n",
    "        Adjacency matrix of the graph.\n",
    "    z : np.array, shape [N]\n",
    "        Cluster indicators for each node.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    norm_cut : float\n",
    "        Value of the normalized cut for the given partition of the graph.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    sum = 0.\n",
    "    for category in range(z.max()):\n",
    "        indices = np.argwhere(z == category).reshape(-1)\n",
    "        mask = np.ones(A.shape[0])\n",
    "        mask[indices] = 0.\n",
    "        cut = np.sum (A[indices]*mask)\n",
    "        \n",
    "        #compute volume of category:\n",
    "        volume = np.sum(A[indices])\n",
    "        if volume is not 0.:\n",
    "            cut = cut/volume\n",
    "        sum  = sum+cut\n",
    "        \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, how using the unnormalized Laplacian leads to a much better ratio cut, while the normalized Laplacian leads to better normalized cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "num_clusters = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "When using L_unnorm:\n",
      " ratio cut = 287.109\n",
      " normalized cut = 4.000\n",
      " sizes of partitions are: [3379, 1, 1, 1, 1, 1]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "norm_laplacian = False\n",
    "z_unnorm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
    "print('When using L_unnorm:')\n",
    "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_unnorm)))\n",
    "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_unnorm)))\n",
    "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_unnorm)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "When using L_norm:\n",
      " ratio cut = 5347.316\n",
      " normalized cut = 4.198\n",
      " sizes of partitions are: [554, 586, 491, 507, 607, 639]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "norm_laplacian = True\n",
    "z_norm = spectral_clustering(A, num_clusters, norm_laplacian)\n",
    "print('When using L_norm:')\n",
    "print(' ratio cut = {:.3f}'.format(compute_ratio_cut(A, z_norm)))\n",
    "print(' normalized cut = {:.3f}'.format(compute_normalized_cut(A, z_norm)))\n",
    "print(' sizes of partitions are: {}'.format([len(clust) for clust in labels_to_list_of_clusters(z_norm)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final part of the assignment, your task is to print out the 5 most popular types of restaurants visited by the users in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_top_categories_for_each_cluster(top_k, z, F, categories):\n",
    "    \"\"\"Print the top-K categories among users in each cluster.\n",
    "    For each cluster, the function prints names of the top-K categories,\n",
    "    and number of users that like the respective category (separated by a comma).\n",
    "    The function doesn't return anything, just prints the output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    top_k : int\n",
    "        Number of most popular categories to print for each cluster.\n",
    "    z : np.array, shape [N]\n",
    "        Cluster labels.\n",
    "    F : sp.csr_matrix, shape [N, C]\n",
    "        Matrix that tells preferences of each user to each category.\n",
    "        F[i, c] = 1 if user i gave at least one positive review to at least one restaurant in category c.\n",
    "    categories : list, shape [C]\n",
    "        Names of the categories.\n",
    "        \n",
    "    \"\"\"\n",
    "    for cluster in range(z.max()):\n",
    "        cluster_votes  = F[np.argwhere(cluster == z).reshape(-1)]\n",
    "        #print(cluster_votes)\n",
    "        cluster_total_votes = np.sum(cluster_votes,axis = 0).reshape(-1)\n",
    "        top_categories_idx = np.argsort(cluster_total_votes)[-top_k:]\n",
    "        #print(top_categories_idx)\n",
    "        print('')\n",
    "        print('Most popular restaurant categories in user group %d:'%int(cluster))\n",
    "        for idx in top_categories_idx:\n",
    "            print('%s. Number of voters: %d'%(categories[idx],cluster_total_votes[idx]))\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n",
      "Most popular restaurant categories in user group 0:\n",
      "Asian Fusion. Number of voters: 399\n",
      "Sandwiches. Number of voters: 433\n",
      "Italian. Number of voters: 449\n",
      "Japanese. Number of voters: 463\n",
      "Breakfast & Brunch. Number of voters: 525\n",
      "\n",
      "Most popular restaurant categories in user group 1:\n",
      "Pizza. Number of voters: 329\n",
      "Sandwiches. Number of voters: 395\n",
      "Italian. Number of voters: 398\n",
      "Japanese. Number of voters: 421\n",
      "Breakfast & Brunch. Number of voters: 441\n",
      "\n",
      "Most popular restaurant categories in user group 2:\n",
      "Asian Fusion. Number of voters: 411\n",
      "Sandwiches. Number of voters: 459\n",
      "Italian. Number of voters: 490\n",
      "Japanese. Number of voters: 499\n",
      "Breakfast & Brunch. Number of voters: 541\n",
      "\n",
      "Most popular restaurant categories in user group 3:\n",
      "Pizza. Number of voters: 307\n",
      "Italian. Number of voters: 349\n",
      "Sandwiches. Number of voters: 353\n",
      "Japanese. Number of voters: 376\n",
      "Breakfast & Brunch. Number of voters: 415\n",
      "\n",
      "Most popular restaurant categories in user group 4:\n",
      "Cafes. Number of voters: 348\n",
      "Sandwiches. Number of voters: 392\n",
      "Japanese. Number of voters: 418\n",
      "Italian. Number of voters: 419\n",
      "Breakfast & Brunch. Number of voters: 467\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "z_norm = spectral_clustering(A, num_clusters, True)\n",
    "r = print_top_categories_for_each_cluster(5, z_norm, F, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}